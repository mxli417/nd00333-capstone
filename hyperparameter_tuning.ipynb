{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning using HyperDrive\n",
        "\n",
        "In the cell below, we import all the dependencies that we need to complete the project."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\n",
        "from azureml.core import (\n",
        "    Workspace,\n",
        "    Experiment, \n",
        "    Dataset, \n",
        "    ComputeTarget,\n",
        "    ScriptRunConfig,\n",
        "    Environment,\n",
        ")\n",
        "\n",
        "from azureml.train.hyperdrive import (\n",
        "    BanditPolicy,\n",
        "    RandomParameterSampling,\n",
        "    choice,\n",
        "    uniform,\n",
        "    loguniform,\n",
        "    HyperDriveConfig,\n",
        "    PrimaryMetricGoal,\n",
        ")\n",
        "\n",
        "from azureml.widgets import RunDetails\n",
        "from azureml.core.model import InferenceConfig, Model\n",
        "from azureml.core.webservice import AciWebservice\n",
        "from azureml.train.sklearn import SKLearn\n",
        "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
        "\n",
        "import joblib\n",
        "import uuid\n",
        "import pandas as pd \n",
        "import requests\n",
        "import json\n",
        "import os"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1691515509823
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup workspace and experiment"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\n",
        "experiment_name = 'capstone-experiment'\n",
        "experiment=Experiment(ws, experiment_name)\n",
        "\n",
        "print(f'Workspace name: {ws.name} / AZ region: {ws.location} ' \\\n",
        "    f'/ Subscription ID: {ws.subscription_id} / Resource group: {ws.resource_group}')\n",
        "\n",
        "run = experiment.start_logging()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Workspace name: quick-starts-ws-239936 / AZ region: westus2 / Subscription ID: 9b72f9e6-56c5-4c16-991b-19c652994860 / Resource group: aml-quickstarts-239936\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1691515519426
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute target assignment"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import AmlCompute\n",
        "\n",
        "cluster_name = \"capstone-cluster\"\n",
        "\n",
        "try:\n",
        "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print(f\"Found existing compute target: {compute_target}\")\n",
        "except Exception as e:\n",
        "    print(f\"Creating a new compute target (error: {e}\")\n",
        "    compute_cnfg = AmlCompute.provisioning_configuration(\n",
        "        vm_size = \"Standard_DS3_V2\",\n",
        "        min_nodes = 0,\n",
        "        max_nodes = 4,\n",
        "    )\n",
        "    compute_target = ComputeTarget.create(\n",
        "        ws,\n",
        "        cluster_name,\n",
        "        compute_cnfg,\n",
        "    )\n",
        "    compute_target.wait_for_completion(\n",
        "        show_output=True,\n",
        "        min_node_count=None,\n",
        "        timeout_in_minutes=60,\n",
        "    )\n",
        "\n",
        "# message if ready\n",
        "print(f'compute target: {compute_target.get_status().serialize()}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing compute target: AmlCompute(workspace=Workspace.create(name='quick-starts-ws-239936', subscription_id='9b72f9e6-56c5-4c16-991b-19c652994860', resource_group='aml-quickstarts-239936'), name=capstone-cluster, id=/subscriptions/9b72f9e6-56c5-4c16-991b-19c652994860/resourceGroups/aml-quickstarts-239936/providers/Microsoft.MachineLearningServices/workspaces/quick-starts-ws-239936/computes/capstone-cluster, type=AmlCompute, provisioning_state=Succeeded, location=westus2, tags={})\ncompute target: {'currentNodeCount': 4, 'targetNodeCount': 3, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 0, 'idleNodeCount': 4, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Resizing', 'allocationStateTransitionTime': '2023-08-08T17:25:13.665000+00:00', 'errors': None, 'creationTime': '2023-08-08T16:38:00.642955+00:00', 'modifiedTime': '2023-08-08T16:38:04.594612+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT1800S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_DS3_V2'}\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1691515519956
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "For our capstone project, we use [the kaggle heart failure dataset](https://www.kaggle.com/datasets/andrewmvd/heart-failure-clinical-data). We uploaded and registered this dataset to the workspace beforehand. The dataset stems from [a publication on heart failure prediction using machine learning](https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-020-1023-5). It contains clinical data and the patient's survival or death as a binary variable. As the variable is binary, we are dealing with a classification problem here."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ds_name = 'heart_failure_kaggle_ml'\n",
        "dataset = Dataset.get_by_name(workspace=ws, name=ds_name)"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1691515524702
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# inspect the dataframe \n",
        "hf_prediction = dataset.to_pandas_dataframe()\n",
        "hf_prediction.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "    age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n0  75.0        0                       582         0                 20   \n1  55.0        0                      7861         0                 38   \n2  65.0        0                       146         0                 20   \n3  50.0        1                       111         0                 20   \n4  65.0        1                       160         1                 20   \n\n   high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n0                    1  265000.00               1.9           130    1   \n1                    0  263358.03               1.1           136    1   \n2                    0  162000.00               1.3           129    1   \n3                    0  210000.00               1.9           137    1   \n4                    0  327000.00               2.7           116    0   \n\n   smoking  time  DEATH_EVENT  \n0        0     4            1  \n1        0     6            1  \n2        1     7            1  \n3        0     7            1  \n4        0     8            1  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>anaemia</th>\n      <th>creatinine_phosphokinase</th>\n      <th>diabetes</th>\n      <th>ejection_fraction</th>\n      <th>high_blood_pressure</th>\n      <th>platelets</th>\n      <th>serum_creatinine</th>\n      <th>serum_sodium</th>\n      <th>sex</th>\n      <th>smoking</th>\n      <th>time</th>\n      <th>DEATH_EVENT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>75.0</td>\n      <td>0</td>\n      <td>582</td>\n      <td>0</td>\n      <td>20</td>\n      <td>1</td>\n      <td>265000.00</td>\n      <td>1.9</td>\n      <td>130</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>55.0</td>\n      <td>0</td>\n      <td>7861</td>\n      <td>0</td>\n      <td>38</td>\n      <td>0</td>\n      <td>263358.03</td>\n      <td>1.1</td>\n      <td>136</td>\n      <td>1</td>\n      <td>0</td>\n      <td>6</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>65.0</td>\n      <td>0</td>\n      <td>146</td>\n      <td>0</td>\n      <td>20</td>\n      <td>0</td>\n      <td>162000.00</td>\n      <td>1.3</td>\n      <td>129</td>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>50.0</td>\n      <td>1</td>\n      <td>111</td>\n      <td>0</td>\n      <td>20</td>\n      <td>0</td>\n      <td>210000.00</td>\n      <td>1.9</td>\n      <td>137</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>65.0</td>\n      <td>1</td>\n      <td>160</td>\n      <td>1</td>\n      <td>20</td>\n      <td>0</td>\n      <td>327000.00</td>\n      <td>2.7</td>\n      <td>116</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1691515531199
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hf_prediction.tail()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "      age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n294  62.0        0                        61         1                 38   \n295  55.0        0                      1820         0                 38   \n296  45.0        0                      2060         1                 60   \n297  45.0        0                      2413         0                 38   \n298  50.0        0                       196         0                 45   \n\n     high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n294                    1   155000.0               1.1           143    1   \n295                    0   270000.0               1.2           139    0   \n296                    0   742000.0               0.8           138    0   \n297                    0   140000.0               1.4           140    1   \n298                    0   395000.0               1.6           136    1   \n\n     smoking  time  DEATH_EVENT  \n294        1   270            0  \n295        0   271            0  \n296        0   278            0  \n297        1   280            0  \n298        1   285            0  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>anaemia</th>\n      <th>creatinine_phosphokinase</th>\n      <th>diabetes</th>\n      <th>ejection_fraction</th>\n      <th>high_blood_pressure</th>\n      <th>platelets</th>\n      <th>serum_creatinine</th>\n      <th>serum_sodium</th>\n      <th>sex</th>\n      <th>smoking</th>\n      <th>time</th>\n      <th>DEATH_EVENT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>294</th>\n      <td>62.0</td>\n      <td>0</td>\n      <td>61</td>\n      <td>1</td>\n      <td>38</td>\n      <td>1</td>\n      <td>155000.0</td>\n      <td>1.1</td>\n      <td>143</td>\n      <td>1</td>\n      <td>1</td>\n      <td>270</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>295</th>\n      <td>55.0</td>\n      <td>0</td>\n      <td>1820</td>\n      <td>0</td>\n      <td>38</td>\n      <td>0</td>\n      <td>270000.0</td>\n      <td>1.2</td>\n      <td>139</td>\n      <td>0</td>\n      <td>0</td>\n      <td>271</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>296</th>\n      <td>45.0</td>\n      <td>0</td>\n      <td>2060</td>\n      <td>1</td>\n      <td>60</td>\n      <td>0</td>\n      <td>742000.0</td>\n      <td>0.8</td>\n      <td>138</td>\n      <td>0</td>\n      <td>0</td>\n      <td>278</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>297</th>\n      <td>45.0</td>\n      <td>0</td>\n      <td>2413</td>\n      <td>0</td>\n      <td>38</td>\n      <td>0</td>\n      <td>140000.0</td>\n      <td>1.4</td>\n      <td>140</td>\n      <td>1</td>\n      <td>1</td>\n      <td>280</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>298</th>\n      <td>50.0</td>\n      <td>0</td>\n      <td>196</td>\n      <td>0</td>\n      <td>45</td>\n      <td>0</td>\n      <td>395000.0</td>\n      <td>1.6</td>\n      <td>136</td>\n      <td>1</td>\n      <td>1</td>\n      <td>285</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1691515534413
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperdrive Configuration\n",
        "\n",
        "We use a Gradient Boosting Classifier here, because we are dealing with tabular data and have a binary variable as the target in our classification problem. This is an additive modeling approach, often providing very good performance, a lot of flexibility, can work with categorical and numerical values as-is and naturally handles missing data. \n",
        "\n",
        "To tune and adapt the basic classifier, we are using HyperDrive to select the best hyperparameters which are here:\n",
        "\n",
        "- the learning rate (default: 0.1, we vary this)\n",
        "- n_estimators, the number of base estimators (decision trees) used in the gradient boosting modeling process\n",
        "\n",
        "We use a bandit early stopping policy, which halts the experiments if there is no more improvement in model accuracy, i.e. the model primary metric of the last run is no within the specified slack factor of the most successful run.\n",
        "\n",
        "To progress through the hyperparameter search space (defined on `n_estimators` and the `learning_rate`) fast and easy, we use a random parameter sampler. This is bc. of its non-exhaustive nature, sampling suitable hyperparameters randomly.\n",
        "\n",
        "To best track our experimentation success, we optimize for the best-possible accuracy (primary metric) w.r.t. the classification problem, to most accurately predict the (non-) survival of patient's based on their clinical data."
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598531923519
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preliminaries\n",
        "primary_metric_name = \"accuracy\"\n",
        "if \"training\" not in os.listdir():\n",
        "    os.mkdir(\"training/\")\n",
        "\n",
        "# setup training environment\n",
        "task_env = Environment.from_pip_requirements(\n",
        "    name=\"venv\", \n",
        "    file_path=\"requirements.txt\"\n",
        ")\n",
        "\n",
        "# policy specification\n",
        "early_termination_policy = BanditPolicy(\n",
        "    evaluation_interval=2, \n",
        "    slack_factor=0.2\n",
        ")\n",
        "\n",
        "# parameter sampler specification\n",
        "param_sampling = RandomParameterSampling(\n",
        "    {\n",
        "        \"--learning_rate\": uniform(0.1, 0.5),\n",
        "        \"--n_estimators\": choice(100, 200, 300, 350),\n",
        "    }\n",
        ")\n",
        "\n",
        "# estimator and hyperdrive config specification\n",
        "estimator = ScriptRunConfig(\n",
        "    source_directory=\"./steps\",\n",
        "    script=\"train.py\",\n",
        "    environment=task_env,\n",
        "    compute_target=compute_target,\n",
        ")\n",
        "\n",
        "hyperdrive_run_config = HyperDriveConfig(\n",
        "    run_config=estimator,\n",
        "    hyperparameter_sampling=param_sampling,\n",
        "    policy=early_termination_policy,\n",
        "    primary_metric_name=\"accuracy\",\n",
        "    primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
        "    max_total_runs=10,\n",
        "    max_concurrent_runs=4,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1691516677056
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hyperdrive_run = experiment.submit(hyperdrive_run_config)"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1691516683969
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Details\n",
        "\n",
        "In the cell below, we use the `RunDetails` widget to show the results of the hyperdrive experiment defined above and look at the best model as well as its properties."
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598544898497
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RunDetails(hyperdrive_run).show()\n",
        "hyperdrive_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_HyperDriveWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO'â€¦",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d27987a517c474db93b5ba58a001c9a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/HD_a4a39d61-19ab-4984-afee-61b5bc108990?wsid=/subscriptions/9b72f9e6-56c5-4c16-991b-19c652994860/resourcegroups/aml-quickstarts-239936/workspaces/quick-starts-ws-239936&tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\", \"run_id\": \"HD_a4a39d61-19ab-4984-afee-61b5bc108990\", \"run_properties\": {\"run_id\": \"HD_a4a39d61-19ab-4984-afee-61b5bc108990\", \"created_utc\": \"2023-08-08T17:44:43.510882Z\", \"properties\": {\"primary_metric_config\": \"{\\\"name\\\":\\\"accuracy\\\",\\\"goal\\\":\\\"maximize\\\"}\", \"resume_from\": \"null\", \"runTemplate\": \"HyperDrive\", \"azureml.runsource\": \"hyperdrive\", \"platform\": \"AML\", \"ContentSnapshotId\": \"22ca1c56-5eff-4320-91f5-649986d889d3\", \"user_agent\": \"python/3.8.5 (Linux-5.15.0-1040-azure-x86_64-with-glibc2.10) msrest/0.7.1 Hyperdrive.Service/1.0.0 Hyperdrive.SDK/core.1.51.0\", \"space_size\": \"infinite_space_size\", \"score\": \"0.88\", \"best_child_run_id\": \"HD_a4a39d61-19ab-4984-afee-61b5bc108990_1\", \"best_metric_status\": \"Succeeded\", \"best_data_container_id\": \"dcid.HD_a4a39d61-19ab-4984-afee-61b5bc108990_1\"}, \"tags\": {\"_aml_system_max_concurrent_jobs\": \"4\", \"_aml_system_max_total_jobs\": \"10\", \"_aml_system_max_duration_minutes\": \"10080\", \"_aml_system_policy_config\": \"{\\\"name\\\":\\\"Bandit\\\",\\\"properties\\\":{\\\"evaluation_interval\\\":2,\\\"delay_evaluation\\\":0,\\\"slack_factor\\\":0.2}}\", \"_aml_system_generator_config\": \"{\\\"name\\\":\\\"RANDOM\\\",\\\"parameter_space\\\":{\\\"--learning_rate\\\":[\\\"uniform\\\",[0.1,0.5]],\\\"--n_estimators\\\":[\\\"choice\\\",[[100,200,300,350]]]},\\\"properties\\\":null}\", \"_aml_system_primary_metric_config\": \"{\\\"name\\\":\\\"accuracy\\\",\\\"goal\\\":\\\"maximize\\\"}\", \"_aml_system_platform_config\": \"{\\\"ServiceAddress\\\": \\\"https://westus2.experiments.azureml.net\\\", \\\"SubscriptionId\\\": \\\"9b72f9e6-56c5-4c16-991b-19c652994860\\\", \\\"ResourceGroupName\\\": \\\"aml-quickstarts-239936\\\", \\\"WorkspaceName\\\": \\\"quick-starts-ws-239936\\\", \\\"ExperimentName\\\": \\\"capstone-experiment\\\", \\\"Definition\\\": {\\\"Configuration\\\": null, \\\"Attribution\\\": null, \\\"TelemetryValues\\\": {\\\"amlClientType\\\": \\\"azureml-sdk-train\\\", \\\"amlClientModule\\\": \\\"[Scrubbed]\\\", \\\"amlClientFunction\\\": \\\"[Scrubbed]\\\", \\\"tenantId\\\": \\\"660b3398-b80e-49d2-bc5b-ac1dc93b5254\\\", \\\"amlClientRequestId\\\": \\\"53c280b3-e57c-4c72-b427-2fe93ce77112\\\", \\\"amlClientSessionId\\\": \\\"e332c96e-e62e-4906-9018-e4139772ec55\\\", \\\"subscriptionId\\\": \\\"9b72f9e6-56c5-4c16-991b-19c652994860\\\", \\\"estimator\\\": \\\"NoneType\\\", \\\"samplingMethod\\\": \\\"RANDOM\\\", \\\"terminationPolicy\\\": \\\"Bandit\\\", \\\"primaryMetricGoal\\\": \\\"maximize\\\", \\\"maxTotalRuns\\\": 10, \\\"maxConcurrentRuns\\\": 4, \\\"maxDurationMinutes\\\": 10080, \\\"vmSize\\\": null}, \\\"Overrides\\\": {\\\"Script\\\": \\\"train.py\\\", \\\"Command\\\": \\\"\\\", \\\"UseAbsolutePath\\\": false, \\\"Arguments\\\": [], \\\"SourceDirectoryDataStore\\\": null, \\\"Framework\\\": 0, \\\"Communicator\\\": 0, \\\"Target\\\": \\\"capstone-cluster\\\", \\\"DataReferences\\\": {}, \\\"Data\\\": {}, \\\"OutputData\\\": {}, \\\"Datacaches\\\": [], \\\"JobName\\\": null, \\\"MaxRunDurationSeconds\\\": 2592000, \\\"NodeCount\\\": 1, \\\"InstanceTypes\\\": [], \\\"Priority\\\": null, \\\"CredentialPassthrough\\\": false, \\\"Identity\\\": null, \\\"Environment\\\": {\\\"Name\\\": \\\"venv\\\", \\\"AutoRebuild\\\": true, \\\"Python\\\": {\\\"InterpreterPath\\\": \\\"python\\\", \\\"UserManagedDependencies\\\": false, \\\"CondaDependencies\\\": {\\\"name\\\": \\\"project_environment\\\", \\\"dependencies\\\": [\\\"python=3.8.13\\\", {\\\"pip\\\": [\\\"azureml\\\", \\\"azureml-core\\\", \\\"azureml-defaults\\\", \\\"joblib\\\", \\\"numpy\\\", \\\"pandas\\\", \\\"scikit-learn\\\"]}, \\\"pip\\\"], \\\"channels\\\": [\\\"anaconda\\\", \\\"conda-forge\\\"]}, \\\"BaseCondaEnvironment\\\": null}, \\\"EnvironmentVariables\\\": {\\\"EXAMPLE_ENV_VAR\\\": \\\"EXAMPLE_VALUE\\\"}, \\\"Docker\\\": {\\\"BaseImage\\\": \\\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20230509.v1\\\", \\\"Platform\\\": {\\\"Os\\\": \\\"Linux\\\", \\\"Architecture\\\": \\\"amd64\\\"}, \\\"BaseDockerfile\\\": null, \\\"BaseImageRegistry\\\": {\\\"Address\\\": null, \\\"Username\\\": null, \\\"Password\\\": null}, \\\"Enabled\\\": false, \\\"Arguments\\\": []}, \\\"Spark\\\": {\\\"Repositories\\\": [], \\\"Packages\\\": [], \\\"PrecachePackages\\\": true}, \\\"InferencingStackVersion\\\": null}, \\\"History\\\": {\\\"OutputCollection\\\": true, \\\"DirectoriesToWatch\\\": [\\\"logs\\\"], \\\"EnableMLflowTracking\\\": true, \\\"snapshotProject\\\": true}, \\\"Spark\\\": {\\\"Configuration\\\": {\\\"spark.app.name\\\": \\\"Azure ML Experiment\\\", \\\"spark.yarn.maxAppAttempts\\\": \\\"1\\\"}}, \\\"ParallelTask\\\": {\\\"MaxRetriesPerWorker\\\": 0, \\\"WorkerCountPerNode\\\": 1, \\\"TerminalExitCodes\\\": null, \\\"Configuration\\\": {}}, \\\"BatchAi\\\": {\\\"NodeCount\\\": 0}, \\\"AmlCompute\\\": {\\\"Name\\\": null, \\\"VmSize\\\": null, \\\"RetainCluster\\\": false, \\\"ClusterMaxNodeCount\\\": null}, \\\"AISuperComputer\\\": {\\\"InstanceType\\\": \\\"D2\\\", \\\"FrameworkImage\\\": null, \\\"ImageVersion\\\": null, \\\"Location\\\": null, \\\"AISuperComputerStorageData\\\": null, \\\"Interactive\\\": false, \\\"ScalePolicy\\\": null, \\\"VirtualClusterArmId\\\": null, \\\"TensorboardLogDirectory\\\": null, \\\"SSHPublicKey\\\": null, \\\"SSHPublicKeys\\\": null, \\\"EnableAzmlInt\\\": true, \\\"Priority\\\": \\\"Medium\\\", \\\"SLATier\\\": \\\"Standard\\\", \\\"UserAlias\\\": null}, \\\"KubernetesCompute\\\": {\\\"InstanceType\\\": null}, \\\"Tensorflow\\\": {\\\"WorkerCount\\\": 1, \\\"ParameterServerCount\\\": 1}, \\\"Mpi\\\": {\\\"ProcessCountPerNode\\\": 1}, \\\"PyTorch\\\": {\\\"CommunicationBackend\\\": \\\"nccl\\\", \\\"ProcessCount\\\": null}, \\\"Hdi\\\": {\\\"YarnDeployMode\\\": 2}, \\\"ContainerInstance\\\": {\\\"Region\\\": null, \\\"CpuCores\\\": 2.0, \\\"MemoryGb\\\": 3.5}, \\\"ExposedPorts\\\": null, \\\"Docker\\\": {\\\"UseDocker\\\": false, \\\"SharedVolumes\\\": true, \\\"ShmSize\\\": \\\"2g\\\", \\\"Arguments\\\": []}, \\\"Cmk8sCompute\\\": {\\\"Configuration\\\": {}}, \\\"CommandReturnCodeConfig\\\": {\\\"ReturnCode\\\": 0, \\\"SuccessfulReturnCodes\\\": []}, \\\"EnvironmentVariables\\\": {}, \\\"ApplicationEndpoints\\\": {}, \\\"Parameters\\\": []}, \\\"SnapshotId\\\": \\\"22ca1c56-5eff-4320-91f5-649986d889d3\\\", \\\"Snapshots\\\": [], \\\"SourceCodeDataReference\\\": null, \\\"ParentRunId\\\": null, \\\"DataContainerId\\\": null, \\\"RunType\\\": null, \\\"DisplayName\\\": null, \\\"EnvironmentAssetId\\\": null, \\\"Properties\\\": {}, \\\"Tags\\\": {}, \\\"AggregatedArtifactPath\\\": null}, \\\"ParentRunId\\\": \\\"HD_a4a39d61-19ab-4984-afee-61b5bc108990\\\"}\", \"_aml_system_resume_child_runs\": \"null\", \"_aml_system_all_jobs_generated\": \"true\", \"_aml_system_cancellation_requested\": \"false\", \"_aml_system_samples_generated_count\": \"10\", \"_aml_system_progress_metadata_evaluation_timestamp\": \"\\\"2023-08-08T17:45:13.155065\\\"\", \"_aml_system_progress_metadata_digest\": \"\\\"a67494da6696656d22b1632513336567f1260b5e320a2568a0f7aecc0b262e3e\\\"\", \"_aml_system_progress_metadata_active_timestamp\": \"\\\"2023-08-08T17:45:13.155065\\\"\", \"_aml_system_optimizer_state_artifact\": \"null\", \"_aml_system_outdated_optimizer_state_artifacts\": \"\\\"[]\\\"\", \"_aml_system_HD_a4a39d61-19ab-4984-afee-61b5bc108990_0\": \"{\\\"--learning_rate\\\": 0.44025352531361095, \\\"--n_estimators\\\": 300}\", \"_aml_system_HD_a4a39d61-19ab-4984-afee-61b5bc108990_1\": \"{\\\"--learning_rate\\\": 0.10642205301112365, \\\"--n_estimators\\\": 100}\", \"_aml_system_HD_a4a39d61-19ab-4984-afee-61b5bc108990_2\": \"{\\\"--learning_rate\\\": 0.33669495164004437, \\\"--n_estimators\\\": 300}\", \"_aml_system_HD_a4a39d61-19ab-4984-afee-61b5bc108990_3\": \"{\\\"--learning_rate\\\": 0.20714945116469952, \\\"--n_estimators\\\": 100}\", \"_aml_system_HD_a4a39d61-19ab-4984-afee-61b5bc108990_4\": \"{\\\"--learning_rate\\\": 0.4167846511768707, \\\"--n_estimators\\\": 350}\", \"_aml_system_HD_a4a39d61-19ab-4984-afee-61b5bc108990_5\": \"{\\\"--learning_rate\\\": 0.4604039826866484, \\\"--n_estimators\\\": 350}\", \"_aml_system_HD_a4a39d61-19ab-4984-afee-61b5bc108990_6\": \"{\\\"--learning_rate\\\": 0.3166472585252633, \\\"--n_estimators\\\": 200}\", \"_aml_system_HD_a4a39d61-19ab-4984-afee-61b5bc108990_7\": \"{\\\"--learning_rate\\\": 0.12538963667287734, \\\"--n_estimators\\\": 300}\", \"_aml_system_HD_a4a39d61-19ab-4984-afee-61b5bc108990_8\": \"{\\\"--learning_rate\\\": 0.22519510195960227, \\\"--n_estimators\\\": 100}\", \"_aml_system_HD_a4a39d61-19ab-4984-afee-61b5bc108990_9\": \"{\\\"--learning_rate\\\": 0.16201468541590722, \\\"--n_estimators\\\": 300}\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2023-08-08T17:48:49.360919Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/hyperdrive.txt\": \"https://mlstrg239936.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_a4a39d61-19ab-4984-afee-61b5bc108990/azureml-logs/hyperdrive.txt?sv=2019-07-07&sr=b&sig=fz9BSj0wQHcq03FwzweBD7Y4nP7OQ5%2FSFoKgY7P5lKs%3D&skoid=e1ca1d8c-b8d7-483a-8896-10e61372c40f&sktid=660b3398-b80e-49d2-bc5b-ac1dc93b5254&skt=2023-08-08T16%3A14%3A53Z&ske=2023-08-10T00%3A24%3A53Z&sks=b&skv=2019-07-07&st=2023-08-08T19%3A49%3A12Z&se=2023-08-09T03%3A59%3A12Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/hyperdrive.txt\"]], \"run_duration\": \"0:04:05\", \"run_number\": \"1691516683\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}, \"hyper_parameters\": {\"--learning_rate\": [\"uniform\", [0.1, 0.5]], \"--n_estimators\": [\"choice\", [[100, 200, 300, 350]]]}}, \"child_runs\": [{\"run_id\": \"HD_a4a39d61-19ab-4984-afee-61b5bc108990_3\", \"run_number\": 1691516685, \"metric\": 0.8, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2023-08-08T17:45:02.20509Z\", \"end_time\": \"2023-08-08T17:45:21.244111Z\", \"created_time\": \"2023-08-08T17:44:45.501188Z\", \"created_time_dt\": \"2023-08-08T17:44:45.501188Z\", \"duration\": \"0:00:35\", \"hyperdrive_id\": \"a4a39d61-19ab-4984-afee-61b5bc108990\", \"arguments\": null, \"param_--learning_rate\": 0.20714945116469952, \"param_--n_estimators\": 100, \"best_metric\": 0.8}, {\"run_id\": \"HD_a4a39d61-19ab-4984-afee-61b5bc108990_5\", \"run_number\": 1691516774, \"metric\": 0.77333333, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2023-08-08T17:46:30.945504Z\", \"end_time\": \"2023-08-08T17:46:46.897022Z\", \"created_time\": \"2023-08-08T17:46:14.74009Z\", \"created_time_dt\": \"2023-08-08T17:46:14.74009Z\", \"duration\": \"0:00:32\", \"hyperdrive_id\": \"a4a39d61-19ab-4984-afee-61b5bc108990\", \"arguments\": null, \"param_--learning_rate\": 0.4604039826866484, \"param_--n_estimators\": 350, \"best_metric\": 0.8}, {\"run_id\": \"HD_a4a39d61-19ab-4984-afee-61b5bc108990_7\", \"run_number\": 1691516775, \"metric\": 0.78666667, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2023-08-08T17:46:31.244065Z\", \"end_time\": \"2023-08-08T17:46:47.406937Z\", \"created_time\": \"2023-08-08T17:46:15.095291Z\", \"created_time_dt\": \"2023-08-08T17:46:15.095291Z\", \"duration\": \"0:00:32\", \"hyperdrive_id\": \"a4a39d61-19ab-4984-afee-61b5bc108990\", \"arguments\": null, \"param_--learning_rate\": 0.12538963667287734, \"param_--n_estimators\": 300, \"best_metric\": 0.8}, {\"run_id\": \"HD_a4a39d61-19ab-4984-afee-61b5bc108990_8\", \"run_number\": 1691516864, \"metric\": 0.82666667, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2023-08-08T17:47:54.353073Z\", \"end_time\": \"2023-08-08T17:48:10.721903Z\", \"created_time\": \"2023-08-08T17:47:44.770666Z\", \"created_time_dt\": \"2023-08-08T17:47:44.770666Z\", \"duration\": \"0:00:25\", \"hyperdrive_id\": \"a4a39d61-19ab-4984-afee-61b5bc108990\", \"arguments\": null, \"param_--learning_rate\": 0.22519510195960227, \"param_--n_estimators\": 100, \"best_metric\": 0.82666667}], \"children_metrics\": {\"categories\": [0], \"series\": {\"learning_rate:\": [{\"categories\": [1691516685, 1691516774, 1691516775, 1691516864], \"mode\": \"markers\", \"name\": \"learning_rate:\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.20714945116469952, 0.4604039826866484, 0.12538963667287734, 0.22519510195960227]}, {\"categories\": [1691516685, 1691516774, 1691516775, 1691516864], \"mode\": \"lines\", \"name\": \"learning_rate:_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.20714945116469952, 0.4604039826866484, 0.4604039826866484, 0.4604039826866484]}], \"n_estimators:\": [{\"categories\": [1691516685, 1691516774, 1691516775, 1691516864], \"mode\": \"markers\", \"name\": \"n_estimators:\", \"stepped\": false, \"type\": \"scatter\", \"data\": [100, 350, 300, 100]}, {\"categories\": [1691516685, 1691516774, 1691516775, 1691516864], \"mode\": \"lines\", \"name\": \"n_estimators:_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [100, 350, 350, 350]}], \"clf_report\": [{\"categories\": [1691516685, 1691516774, 1691516775, 1691516864], \"mode\": \"markers\", \"name\": \"clf_report\", \"stepped\": false, \"type\": \"scatter\", \"data\": [\"              precision    recall  f1-score   support\\n\\n           0       0.83      0.88      0.86        51\\n           1       0.71      0.62      0.67        24\\n\\n    accuracy                           0.80        75\\n   macro avg       0.77      0.75      0.76        75\\nweighted avg       0.80      0.80      0.80        75\\n\", \"              precision    recall  f1-score   support\\n\\n           0       0.87      0.78      0.82        51\\n           1       0.62      0.75      0.68        24\\n\\n    accuracy                           0.77        75\\n   macro avg       0.75      0.77      0.75        75\\nweighted avg       0.79      0.77      0.78        75\\n\", \"              precision    recall  f1-score   support\\n\\n           0       0.86      0.82      0.84        51\\n           1       0.65      0.71      0.68        24\\n\\n    accuracy                           0.79        75\\n   macro avg       0.76      0.77      0.76        75\\nweighted avg       0.79      0.79      0.79        75\\n\", \"              precision    recall  f1-score   support\\n\\n           0       0.84      0.92      0.88        51\\n           1       0.79      0.62      0.70        24\\n\\n    accuracy                           0.83        75\\n   macro avg       0.81      0.77      0.79        75\\nweighted avg       0.82      0.83      0.82        75\\n\"]}, {\"categories\": [1691516685, 1691516774, 1691516775, 1691516864], \"mode\": \"lines\", \"name\": \"clf_report_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": []}], \"accuracy\": [{\"categories\": [1691516685, 1691516774, 1691516775, 1691516864], \"mode\": \"markers\", \"name\": \"accuracy\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.8, 0.7733333333333333, 0.7866666666666666, 0.8266666666666667]}, {\"categories\": [1691516685, 1691516774, 1691516775, 1691516864], \"mode\": \"lines\", \"name\": \"accuracy_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.8, 0.8, 0.8, 0.8266666666666667]}]}, \"metricName\": null, \"primaryMetricName\": \"accuracy\", \"showLegend\": false}, \"run_metrics\": [{\"name\": \"best_child_by_primary_metric\", \"run_id\": \"HD_a4a39d61-19ab-4984-afee-61b5bc108990\", \"categories\": [0], \"series\": [{\"data\": [{\"time_elapse\": [60, 91, 244], \"metric_value\": [0.8533333333333334, 0.88, 0.88], \"metric_name\": [\"accuracy\", \"accuracy\", \"accuracy\"], \"run_id\": [\"HD_a4a39d61-19ab-4984-afee-61b5bc108990_2\", \"HD_a4a39d61-19ab-4984-afee-61b5bc108990_1\", \"HD_a4a39d61-19ab-4984-afee-61b5bc108990_1\"], \"final\": [false, false, true]}]}]}], \"run_logs\": \"[2023-08-08T17:44:44.353258][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space\\n[2023-08-08T17:44:44.8416297Z][SCHEDULER][INFO]Scheduling job, id='HD_a4a39d61-19ab-4984-afee-61b5bc108990_0' \\n[2023-08-08T17:44:45.1404992Z][SCHEDULER][INFO]Scheduling job, id='HD_a4a39d61-19ab-4984-afee-61b5bc108990_1' \\n[2023-08-08T17:44:45.1383271Z][SCHEDULER][INFO]Scheduling job, id='HD_a4a39d61-19ab-4984-afee-61b5bc108990_2' \\n[2023-08-08T17:44:45.094455][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.\\n[2023-08-08T17:44:45.2817621Z][SCHEDULER][INFO]Scheduling job, id='HD_a4a39d61-19ab-4984-afee-61b5bc108990_3' \\n[2023-08-08T17:44:45.3532239Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_a4a39d61-19ab-4984-afee-61b5bc108990_1' \\n[2023-08-08T17:44:45.2908869Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_a4a39d61-19ab-4984-afee-61b5bc108990_0' \\n[2023-08-08T17:44:45.3920818Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_a4a39d61-19ab-4984-afee-61b5bc108990_2' \\n[2023-08-08T17:44:45.6035818Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_a4a39d61-19ab-4984-afee-61b5bc108990_3' \\n[2023-08-08T17:46:14.160666][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space\\n[2023-08-08T17:46:14.5391257Z][SCHEDULER][INFO]Scheduling job, id='HD_a4a39d61-19ab-4984-afee-61b5bc108990_4' \\n[2023-08-08T17:46:14.6003125Z][SCHEDULER][INFO]Scheduling job, id='HD_a4a39d61-19ab-4984-afee-61b5bc108990_5' \\n[2023-08-08T17:46:14.7544860Z][SCHEDULER][INFO]Scheduling job, id='HD_a4a39d61-19ab-4984-afee-61b5bc108990_6' \\n[2023-08-08T17:46:14.7855280Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_a4a39d61-19ab-4984-afee-61b5bc108990_4' \\n[2023-08-08T17:46:14.8286048Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_a4a39d61-19ab-4984-afee-61b5bc108990_5' \\n[2023-08-08T17:46:14.9069881Z][SCHEDULER][INFO]Scheduling job, id='HD_a4a39d61-19ab-4984-afee-61b5bc108990_7' \\n[2023-08-08T17:46:14.791451][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.\\n[2023-08-08T17:46:15.0784054Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_a4a39d61-19ab-4984-afee-61b5bc108990_6' \\n[2023-08-08T17:46:15.1747793Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_a4a39d61-19ab-4984-afee-61b5bc108990_7' \\n[2023-08-08T17:47:44.207850][GENERATOR][INFO]Trying to sample '2' jobs from the hyperparameter space\\n[2023-08-08T17:47:44.5084732Z][SCHEDULER][INFO]Scheduling job, id='HD_a4a39d61-19ab-4984-afee-61b5bc108990_8' \\n[2023-08-08T17:47:44.6406475Z][SCHEDULER][INFO]Scheduling job, id='HD_a4a39d61-19ab-4984-afee-61b5bc108990_9' \\n[2023-08-08T17:47:44.601396][GENERATOR][INFO]Successfully sampled '2' jobs, they will soon be submitted to the execution target.\\n[2023-08-08T17:47:44.8683694Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_a4a39d61-19ab-4984-afee-61b5bc108990_8' \\n[2023-08-08T17:47:44.9397533Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_a4a39d61-19ab-4984-afee-61b5bc108990_9' \\n[2023-08-08T17:48:14.148682][GENERATOR][INFO]Max number of jobs '10' reached for experiment.\\n[2023-08-08T17:48:14.366642][GENERATOR][INFO]All jobs generated.\\n[2023-08-08T17:48:49.775677][CONTROLLER][INFO]Experiment was 'ExperimentStatus.RUNNING', is 'ExperimentStatus.FINISHED'.\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.51.0\"}, \"loading\": false}"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "RunId: HD_a4a39d61-19ab-4984-afee-61b5bc108990\nWeb View: https://ml.azure.com/runs/HD_a4a39d61-19ab-4984-afee-61b5bc108990?wsid=/subscriptions/9b72f9e6-56c5-4c16-991b-19c652994860/resourcegroups/aml-quickstarts-239936/workspaces/quick-starts-ws-239936&tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\n\nStreaming azureml-logs/hyperdrive.txt\n=====================================\n\n[2023-08-08T17:44:44.353258][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space\n[2023-08-08T17:44:44.8416297Z][SCHEDULER][INFO]Scheduling job, id='HD_a4a39d61-19ab-4984-afee-61b5bc108990_0' \n[2023-08-08T17:44:45.1404992Z][SCHEDULER][INFO]Scheduling job, id='HD_a4a39d61-19ab-4984-afee-61b5bc108990_1' \n[2023-08-08T17:44:45.1383271Z][SCHEDULER][INFO]Scheduling job, id='HD_a4a39d61-19ab-4984-afee-61b5bc108990_2' \n[2023-08-08T17:44:45.094455][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.\n[2023-08-08T17:44:45.2817621Z][SCHEDULER][INFO]Scheduling job, id='HD_a4a39d61-19ab-4984-afee-61b5bc108990_3' \n[2023-08-08T17:44:45.3532239Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_a4a39d61-19ab-4984-afee-61b5bc108990_1' \n[2023-08-08T17:44:45.2908869Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_a4a39d61-19ab-4984-afee-61b5bc108990_0' \n[2023-08-08T17:44:45.3920818Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_a4a39d61-19ab-4984-afee-61b5bc108990_2' \n[2023-08-08T17:44:45.6035818Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_a4a39d61-19ab-4984-afee-61b5bc108990_3' \n[2023-08-08T17:46:14.160666][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space\n[2023-08-08T17:46:14.5391257Z][SCHEDULER][INFO]Scheduling job, id='HD_a4a39d61-19ab-4984-afee-61b5bc108990_4' \n[2023-08-08T17:46:14.6003125Z][SCHEDULER][INFO]Scheduling job, id='HD_a4a39d61-19ab-4984-afee-61b5bc108990_5' \n[2023-08-08T17:46:14.7544860Z][SCHEDULER][INFO]Scheduling job, id='HD_a4a39d61-19ab-4984-afee-61b5bc108990_6' \n[2023-08-08T17:46:14.7855280Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_a4a39d61-19ab-4984-afee-61b5bc108990_4' \n[2023-08-08T17:46:14.8286048Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_a4a39d61-19ab-4984-afee-61b5bc108990_5' \n[2023-08-08T17:46:14.9069881Z][SCHEDULER][INFO]Scheduling job, id='HD_a4a39d61-19ab-4984-afee-61b5bc108990_7' \n[2023-08-08T17:46:14.791451][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.\n[2023-08-08T17:46:15.0784054Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_a4a39d61-19ab-4984-afee-61b5bc108990_6' \n[2023-08-08T17:46:15.1747793Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_a4a39d61-19ab-4984-afee-61b5bc108990_7' \n[2023-08-08T17:47:44.207850][GENERATOR][INFO]Trying to sample '2' jobs from the hyperparameter space\n[2023-08-08T17:47:44.5084732Z][SCHEDULER][INFO]Scheduling job, id='HD_a4a39d61-19ab-4984-afee-61b5bc108990_8' \n[2023-08-08T17:47:44.6406475Z][SCHEDULER][INFO]Scheduling job, id='HD_a4a39d61-19ab-4984-afee-61b5bc108990_9' \n[2023-08-08T17:47:44.601396][GENERATOR][INFO]Successfully sampled '2' jobs, they will soon be submitted to the execution target.\n[2023-08-08T17:47:44.8683694Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_a4a39d61-19ab-4984-afee-61b5bc108990_8' \n[2023-08-08T17:47:44.9397533Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_a4a39d61-19ab-4984-afee-61b5bc108990_9' \n[2023-08-08T17:48:14.148682][GENERATOR][INFO]Max number of jobs '10' reached for experiment.\n[2023-08-08T17:48:14.366642][GENERATOR][INFO]All jobs generated.\n[2023-08-08T17:48:49.775677][CONTROLLER][INFO]Experiment was 'ExperimentStatus.RUNNING', is 'ExperimentStatus.FINISHED'.\n\nExecution Summary\n=================\nRunId: HD_a4a39d61-19ab-4984-afee-61b5bc108990\nWeb View: https://ml.azure.com/runs/HD_a4a39d61-19ab-4984-afee-61b5bc108990?wsid=/subscriptions/9b72f9e6-56c5-4c16-991b-19c652994860/resourcegroups/aml-quickstarts-239936/workspaces/quick-starts-ws-239936&tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\n\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "{'runId': 'HD_a4a39d61-19ab-4984-afee-61b5bc108990',\n 'target': 'capstone-cluster',\n 'status': 'Completed',\n 'startTimeUtc': '2023-08-08T17:44:43.607508Z',\n 'endTimeUtc': '2023-08-08T17:48:49.360919Z',\n 'services': {},\n 'properties': {'primary_metric_config': '{\"name\":\"accuracy\",\"goal\":\"maximize\"}',\n  'resume_from': 'null',\n  'runTemplate': 'HyperDrive',\n  'azureml.runsource': 'hyperdrive',\n  'platform': 'AML',\n  'ContentSnapshotId': '22ca1c56-5eff-4320-91f5-649986d889d3',\n  'user_agent': 'python/3.8.5 (Linux-5.15.0-1040-azure-x86_64-with-glibc2.10) msrest/0.7.1 Hyperdrive.Service/1.0.0 Hyperdrive.SDK/core.1.51.0',\n  'space_size': 'infinite_space_size',\n  'score': '0.88',\n  'best_child_run_id': 'HD_a4a39d61-19ab-4984-afee-61b5bc108990_1',\n  'best_metric_status': 'Succeeded',\n  'best_data_container_id': 'dcid.HD_a4a39d61-19ab-4984-afee-61b5bc108990_1'},\n 'inputDatasets': [],\n 'outputDatasets': [],\n 'runDefinition': {'configuration': None,\n  'attribution': None,\n  'telemetryValues': {'amlClientType': 'azureml-sdk-train',\n   'amlClientModule': '[Scrubbed]',\n   'amlClientFunction': '[Scrubbed]',\n   'tenantId': '660b3398-b80e-49d2-bc5b-ac1dc93b5254',\n   'amlClientRequestId': '53c280b3-e57c-4c72-b427-2fe93ce77112',\n   'amlClientSessionId': 'e332c96e-e62e-4906-9018-e4139772ec55',\n   'subscriptionId': '9b72f9e6-56c5-4c16-991b-19c652994860',\n   'estimator': 'NoneType',\n   'samplingMethod': 'RANDOM',\n   'terminationPolicy': 'Bandit',\n   'primaryMetricGoal': 'maximize',\n   'maxTotalRuns': 10,\n   'maxConcurrentRuns': 4,\n   'maxDurationMinutes': 10080,\n   'vmSize': None},\n  'snapshotId': '22ca1c56-5eff-4320-91f5-649986d889d3',\n  'snapshots': [],\n  'sourceCodeDataReference': None,\n  'parentRunId': None,\n  'dataContainerId': None,\n  'runType': None,\n  'displayName': None,\n  'environmentAssetId': None,\n  'properties': {},\n  'tags': {},\n  'aggregatedArtifactPath': None},\n 'logFiles': {'azureml-logs/hyperdrive.txt': 'https://mlstrg239936.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_a4a39d61-19ab-4984-afee-61b5bc108990/azureml-logs/hyperdrive.txt?sv=2019-07-07&sr=b&sig=o5P3JEC0wCNBnJxsqbR2tB2E4GMrELD%2B4%2Ftne%2Botucs%3D&skoid=e1ca1d8c-b8d7-483a-8896-10e61372c40f&sktid=660b3398-b80e-49d2-bc5b-ac1dc93b5254&skt=2023-08-08T16%3A14%3A53Z&ske=2023-08-10T00%3A24%3A53Z&sks=b&skv=2019-07-07&st=2023-08-08T17%3A39%3A10Z&se=2023-08-09T01%3A49%3A10Z&sp=r'},\n 'submittedBy': 'ODL_User 239936'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1691516973176
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Model\n",
        "\n",
        "In the cell below, get the best model from the hyperdrive experiments and display all the properties of the model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "brun = hyperdrive_run.get_best_run_by_primary_metric()\n",
        "print(f\"ID for best model run: {brun.id}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "ID for best model run: HD_a4a39d61-19ab-4984-afee-61b5bc108990_1\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1691517244839
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "brun_metrics = brun.get_metrics()\n",
        "print(f\"Best metrics collected from the best run: {brun_metrics}\")\n",
        "print(f\"Reached accuracy: {brun_metrics['accuracy']}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Best metrics collected from the best run: {'learning_rate:': 0.10642205301112365, 'n_estimators:': 100, 'clf_report': '              precision    recall  f1-score   support\\n\\n           0       0.89      0.94      0.91        51\\n           1       0.86      0.75      0.80        24\\n\\n    accuracy                           0.88        75\\n   macro avg       0.87      0.85      0.86        75\\nweighted avg       0.88      0.88      0.88        75\\n', 'accuracy': 0.88}\nReached accuracy: 0.88\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1691517250834
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# display best run details\n",
        "print(brun)\n",
        "brun"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Run(Experiment: capstone-experiment,\nId: HD_a4a39d61-19ab-4984-afee-61b5bc108990_1,\nType: azureml.scriptrun,\nStatus: Completed)\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "Run(Experiment: capstone-experiment,\nId: HD_a4a39d61-19ab-4984-afee-61b5bc108990_1,\nType: azureml.scriptrun,\nStatus: Completed)",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>capstone-experiment</td><td>HD_a4a39d61-19ab-4984-afee-61b5bc108990_1</td><td>azureml.scriptrun</td><td>Completed</td><td><a href=\"https://ml.azure.com/runs/HD_a4a39d61-19ab-4984-afee-61b5bc108990_1?wsid=/subscriptions/9b72f9e6-56c5-4c16-991b-19c652994860/resourcegroups/aml-quickstarts-239936/workspaces/quick-starts-ws-239936&amp;tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.run.Run?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1691517267501
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we save the model along with all other hd-run files."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "brun.get_file_names()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 19,
          "data": {
            "text/plain": "['outputs/model.joblib',\n 'system_logs/cs_capability/cs-capability.log',\n 'system_logs/hosttools_capability/hosttools-capability.log',\n 'system_logs/lifecycler/execution-wrapper.log',\n 'system_logs/lifecycler/lifecycler.log',\n 'system_logs/metrics_capability/metrics-capability.log',\n 'system_logs/snapshot_capability/snapshot-capability.log',\n 'user_logs/std_log.txt']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1691517366813
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "brun.download_files(\"./outputs\")"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1691517416266
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Deployment\n",
        "\n",
        "Remember you have to deploy only one of the two models you trained but you still need to register both the models. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
        "\n",
        "As the model created here is equally good as the AutoML model, we chose to register and directly use it here in the cells below."
      ],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = brun.register_model(\n",
        "    model_name=\"hyperdrive_model\",\n",
        "    model_path=\"./outputs/model.joblib\"\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1691521071479
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To make use of the model in an endpoint, we first create an Aci Webservice deployment and inference config and then deploy the model here. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "task_env = Environment.from_pip_requirements(\n",
        "    name=\"venv\", \n",
        "    file_path=\"requirements.txt\"\n",
        ")\n",
        "\n",
        "deployment_config = AciWebservice.deploy_configuration(\n",
        "    cpu_cores=1,\n",
        "    memory_gb=1,\n",
        ")\n",
        "\n",
        "inference_config = InferenceConfig(\n",
        "    entry_script=\"score.py\",\n",
        "    environment=task_env,\n",
        ")\n",
        "\n",
        "service = Model.deploy(\n",
        "    ws,\n",
        "    \"capstone-service\",\n",
        "    [model],\n",
        "    inference_config,\n",
        "    deployment_config,\n",
        "    overwrite=True,\n",
        ")\n",
        "\n",
        "service.wait_for_deployment(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "azureml.core.model:\nTo leverage new model deployment capabilities, AzureML recommends using CLI/SDK v2 to deploy models as online endpoint, \nplease refer to respective documentations \nhttps://docs.microsoft.com/azure/machine-learning/how-to-deploy-managed-online-endpoints /\nhttps://docs.microsoft.com/azure/machine-learning/how-to-attach-kubernetes-anywhere \nFor more information on migration, see https://aka.ms/acimoemigration \nTo disable CLI/SDK v1 deprecation warning set AZUREML_LOG_DEPRECATION_WARNING_ENABLED to 'False'\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\nRunning\n2023-08-08 19:06:52+00:00 Creating Container Registry if not exists.\n2023-08-08 19:06:52+00:00 Registering the environment.\n2023-08-08 19:06:53+00:00 Use the existing image.\n2023-08-08 19:06:53+00:00 Generating deployment configuration.\n2023-08-08 19:06:54+00:00 Submitting deployment to compute.\n2023-08-08 19:06:56+00:00 Checking the status of deployment capstone-service..\n2023-08-08 19:15:12+00:00 Checking the status of inference endpoint capstone-service.\nSucceeded\nACI service creation operation finished, operation \"Succeeded\"\n"
        }
      ],
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1691522114209
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(service.get_logs())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "/bin/bash: /azureml-envs/azureml_58f440cd5db21b9ab3c363f087e7b355/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n/bin/bash: /azureml-envs/azureml_58f440cd5db21b9ab3c363f087e7b355/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n/bin/bash: /azureml-envs/azureml_58f440cd5db21b9ab3c363f087e7b355/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n2023-08-08T19:14:12,767994423+00:00 - rsyslog/run \n2023-08-08T19:14:12,776993918+00:00 - gunicorn/run \nbash: /azureml-envs/azureml_58f440cd5db21b9ab3c363f087e7b355/lib/libtinfo.so.6: no version information available (required by bash)\n2023-08-08T19:14:12,781754615+00:00 | gunicorn/run | \n2023-08-08T19:14:12,783397515+00:00 | gunicorn/run | ###############################################\n2023-08-08T19:14:12,784923414+00:00 | gunicorn/run | AzureML Container Runtime Information\n2023-08-08T19:14:12,790125411+00:00 | gunicorn/run | ###############################################\n2023-08-08T19:14:12,791653610+00:00 | gunicorn/run | \n2023-08-08T19:14:12,796977407+00:00 | gunicorn/run | \n2023-08-08T19:14:12,808835200+00:00 | gunicorn/run | AzureML image information: openmpi4.1.0-ubuntu20.04, Materializaton Build:20230509.v1\n2023-08-08T19:14:12,808835200+00:00 - nginx/run \n2023-08-08T19:14:12,813653297+00:00 | gunicorn/run | \n2023-08-08T19:14:12,815189997+00:00 | gunicorn/run | \n2023-08-08T19:14:12,821846593+00:00 | gunicorn/run | PATH environment variable: /azureml-envs/azureml_58f440cd5db21b9ab3c363f087e7b355/bin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n2023-08-08T19:14:12,823354993+00:00 | gunicorn/run | PYTHONPATH environment variable: \n2023-08-08T19:14:12,824791493+00:00 | gunicorn/run | \n2023-08-08T19:14:14,288170195+00:00 | gunicorn/run | CONDAPATH environment variable: /opt/miniconda\n\n# conda environments:\n#\n                      *  /azureml-envs/azureml_58f440cd5db21b9ab3c363f087e7b355\nbase                     /opt/miniconda\n\n2023-08-08T19:14:16,554865995+00:00 | gunicorn/run | \n2023-08-08T19:14:16,559377595+00:00 | gunicorn/run | Pip Dependencies (before dynamic installation)\n\nadal==1.2.7\nargcomplete==2.1.2\nattrs==23.1.0\nazure-common==1.1.28\nazure-core==1.28.0\nazure-graphrbac==0.61.1\nazure-identity==1.13.0\nazure-mgmt-authorization==3.0.0\nazure-mgmt-containerregistry==10.1.0\nazure-mgmt-core==1.4.0\nazure-mgmt-keyvault==10.2.3\nazure-mgmt-resource==22.0.0\nazure-mgmt-storage==21.0.0\nazureml==0.2.7\nazureml-core==1.52.0\nazureml-dataprep==4.11.7\nazureml-dataprep-native==38.0.0\nazureml-dataprep-rslex==2.18.6\nazureml-dataset-runtime==1.52.0\nazureml-defaults==1.52.0\nazureml-inference-server-http==0.8.4\nbackports.tempfile==1.0\nbackports.weakref==1.0.post1\nbcrypt==4.0.1\ncachetools==5.3.1\ncertifi @ file:///croot/certifi_1671487769961/work/certifi\ncffi==1.15.1\ncharset-normalizer==3.2.0\nclick==8.1.6\ncloudpickle==2.2.1\ncontextlib2==21.6.0\ncryptography==41.0.3\ndistro==1.8.0\ndocker==6.1.3\ndotnetcore2==3.1.23\nFlask==2.2.5\nFlask-Cors==3.0.10\nfusepy==3.0.1\ngoogle-api-core==2.11.1\ngoogle-auth==2.22.0\ngoogleapis-common-protos==1.60.0\ngunicorn==20.1.0\nhumanfriendly==10.0\nidna==3.4\nimportlib-metadata==6.8.0\nimportlib-resources==6.0.1\ninference-schema==1.5.1\nisodate==0.6.1\nitsdangerous==2.1.2\njeepney==0.8.0\nJinja2==3.1.2\njmespath==1.0.1\njoblib==1.3.1\njsonpickle==3.0.1\njsonschema==4.19.0\njsonschema-specifications==2023.7.1\nknack==0.10.1\nMarkupSafe==2.1.3\nmsal==1.23.0\nmsal-extensions==1.0.0\nmsrest==0.7.1\nmsrestazure==0.6.4\nndg-httpsclient==0.5.1\nnumpy==1.23.5\noauthlib==3.2.2\nopencensus==0.11.2\nopencensus-context==0.1.3\nopencensus-ext-azure==1.1.9\npackaging==23.0\npandas==2.0.3\nparamiko==3.3.1\npathspec==0.11.2\npkginfo==1.9.6\npkgutil_resolve_name==1.3.10\nportalocker==2.7.0\nprotobuf==4.23.4\npsutil==5.9.5\npyarrow==11.0.0\npyasn1==0.5.0\npyasn1-modules==0.3.0\npycparser==2.21\npydantic==1.10.12\nPygments==2.16.1\nPyJWT==2.8.0\nPyNaCl==1.5.0\npyOpenSSL==23.2.0\nPySocks==1.7.1\npython-dateutil==2.8.2\npytz==2023.3\nPyYAML==6.0.1\nreferencing==0.30.2\nrequests==2.31.0\nrequests-oauthlib==1.3.1\nrpds-py==0.9.2\nrsa==4.9\nscikit-learn==1.3.0\nscipy==1.10.1\nSecretStorage==3.3.3\nsix==1.16.0\ntabulate==0.9.0\nthreadpoolctl==3.2.0\ntyping_extensions==4.7.1\ntzdata==2023.3\nurllib3==1.26.16\nwebsocket-client==1.6.1\nWerkzeug==2.3.6\nwrapt==1.12.1\nzipp==3.16.2\n\n2023-08-08T19:14:17,955881295+00:00 | gunicorn/run | \n2023-08-08T19:14:17,957978195+00:00 | gunicorn/run | ###############################################\n2023-08-08T19:14:17,962362295+00:00 | gunicorn/run | Checking if the Python package azureml-inference-server-http is installed\n2023-08-08T19:14:17,964241395+00:00 | gunicorn/run | ###############################################\n2023-08-08T19:14:17,965885995+00:00 | gunicorn/run | \n2023-08-08T19:14:19,958223873+00:00 | gunicorn/run | \n2023-08-08T19:14:19,964597602+00:00 | gunicorn/run | ###############################################\n2023-08-08T19:14:19,967574102+00:00 | gunicorn/run | AzureML Inference Server\n2023-08-08T19:14:19,969875557+00:00 | gunicorn/run | ###############################################\n2023-08-08T19:14:19,976240386+00:00 | gunicorn/run | \n2023-08-08T19:14:21,922080824+00:00 | gunicorn/run | Starting AzureML Inference Server HTTP.\n2023-08-08 19:14:22,336 I [75] azmlinfsrv - Loaded logging config from /azureml-envs/azureml_58f440cd5db21b9ab3c363f087e7b355/lib/python3.8/site-packages/azureml_inference_server_http/logging.json\n2023-08-08 19:14:22,603 I [75] gunicorn.error - Starting gunicorn 20.1.0\n2023-08-08 19:14:22,604 I [75] gunicorn.error - Listening at: http://0.0.0.0:31311 (75)\n2023-08-08 19:14:22,604 I [75] gunicorn.error - Using worker: sync\n2023-08-08 19:14:22,610 I [142] gunicorn.error - Booting worker with pid: 142\n/azureml-envs/azureml_58f440cd5db21b9ab3c363f087e7b355/lib/python3.8/site-packages/azureml_inference_server_http/server/config.py:51: FutureWarning: aliases are no longer used by BaseSettings to define which environment variables to read. Instead use the \"env\" field setting. See https://pydantic-docs.helpmanual.io/usage/settings/#environment-variable-names\n  class AMLInferenceServerConfig(pydantic.BaseSettings):\n\nAzure ML Inferencing HTTP server v0.8.4\n\n\nServer Settings\n---------------\nEntry Script Name: /var/azureml-app/score.py\nModel Directory: /var/azureml-app/azureml-models/hyperdrive_model/3\nConfig File: None\nWorker Count: 1\nWorker Timeout (seconds): 300\nServer Port: 31311\nHealth Port: 31311\nApplication Insights Enabled: false\nApplication Insights Key: None\nInferencing HTTP server version: azmlinfsrv/0.8.4\nCORS for the specified origins: None\nCreate dedicated endpoint for health: None\n\n\nServer Routes\n---------------\nLiveness Probe: GET   127.0.0.1:31311/\nScore:          POST  127.0.0.1:31311/score\n\n2023-08-08 19:14:23,496 I [142] azmlinfsrv - AML_FLASK_ONE_COMPATIBILITY is set. Patched Flask to ensure compatibility with Flask 1.\nInitializing logger\n2023-08-08 19:14:23,502 I [142] azmlinfsrv - Starting up app insights client\n2023-08-08 19:14:24,679 I [142] azmlinfsrv.user_script - Found user script at /var/azureml-app/score.py\n2023-08-08 19:14:24,679 I [142] azmlinfsrv.user_script - run() is not decorated. Server will invoke it with the input in JSON string.\n2023-08-08 19:14:24,680 I [142] azmlinfsrv.user_script - Invoking user's init function\n2023-08-08 19:14:24,680 I [142] azmlinfsrv.print - Loading model from path.\n2023-08-08 19:14:26,005 I [142] azmlinfsrv.print - Loading successful.\n2023-08-08 19:14:26,006 I [142] azmlinfsrv.user_script - Users's init has completed successfully\n2023-08-08 19:14:26,008 I [142] azmlinfsrv.swagger - Swaggers are prepared for the following versions: [2, 3, 3.1].\n2023-08-08 19:14:26,008 I [142] azmlinfsrv - Scoring timeout is set to 60000\n2023-08-08 19:15:12,285 W [142] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n2023-08-08 19:15:12,286 I [142] gunicorn.access - 127.0.0.1 - - [08/Aug/2023:19:15:12 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"Go-http-client/1.1\"\n2023-08-08 19:15:12,292 W [142] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n2023-08-08 19:15:12,293 I [142] azmlinfsrv - GET /swagger.json 200 1.259ms 2210\n2023-08-08 19:15:12,294 I [142] gunicorn.access - 127.0.0.1 - - [08/Aug/2023:19:15:12 +0000] \"GET /swagger.json HTTP/1.0\" 200 2210 \"-\" \"Go-http-client/1.1\"\n2023-08-08 19:15:13,209 W [142] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n2023-08-08 19:15:13,211 I [142] gunicorn.access - 127.0.0.1 - - [08/Aug/2023:19:15:13 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"Go-http-client/1.1\"\n2023-08-08 19:15:13,218 W [142] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n2023-08-08 19:15:13,219 I [142] azmlinfsrv - GET /swagger.json 200 1.102ms 2210\n2023-08-08 19:15:13,220 I [142] gunicorn.access - 127.0.0.1 - - [08/Aug/2023:19:15:13 +0000] \"GET /swagger.json HTTP/1.0\" 200 2210 \"-\" \"Go-http-client/1.1\"\n\n"
        }
      ],
      "execution_count": 28,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1691522115006
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the cell below, we test the service with three random rows from the dataset:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_var = \"DEATH_EVENT\"\n",
        "json_payload = {\n",
        "    \"data\": hf_prediction.drop(columns=target_var).sample(n=3).to_dict(\"records\")\n",
        "}\n",
        "\n",
        "raw_data = json.dumps(json_payload)\n",
        "print(raw_data)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{\"data\": [{\"age\": 61.0, \"anaemia\": 0, \"creatinine_phosphokinase\": 582, \"diabetes\": 1, \"ejection_fraction\": 38, \"high_blood_pressure\": 0, \"platelets\": 147000.0, \"serum_creatinine\": 1.2, \"serum_sodium\": 141, \"sex\": 1, \"smoking\": 0, \"time\": 237}, {\"age\": 66.0, \"anaemia\": 1, \"creatinine_phosphokinase\": 68, \"diabetes\": 1, \"ejection_fraction\": 38, \"high_blood_pressure\": 1, \"platelets\": 162000.0, \"serum_creatinine\": 1.0, \"serum_sodium\": 136, \"sex\": 0, \"smoking\": 0, \"time\": 95}, {\"age\": 70.0, \"anaemia\": 0, \"creatinine_phosphokinase\": 212, \"diabetes\": 1, \"ejection_fraction\": 17, \"high_blood_pressure\": 1, \"platelets\": 389000.0, \"serum_creatinine\": 1.0, \"serum_sodium\": 136, \"sex\": 1, \"smoking\": 1, \"time\": 188}]}\n"
        }
      ],
      "execution_count": 35,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1691522477844
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we use requests lib to consume endpoint\n",
        "req_headers = {\"Content-Type\": \"application/json\"}\n",
        "uri = service.scoring_uri\n",
        "\n",
        "print(f\"Service scoring URI: {uri}\")\n",
        "response = requests.post(uri, data=raw_data, headers=req_headers)\n",
        "print(response.json())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Service scoring URI: http://1295abf5-d570-47ef-975f-bd6effe28af4.westus2.azurecontainer.io/score\n[0, 0, 0]\n"
        }
      ],
      "execution_count": 36,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1691522478975
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we get three predictions back, all indicating that the patients' will not suffer from death by heart failure."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the cell below, we print the logs of the web service and delete the service"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(service.get_logs())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "/bin/bash: /azureml-envs/azureml_58f440cd5db21b9ab3c363f087e7b355/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n/bin/bash: /azureml-envs/azureml_58f440cd5db21b9ab3c363f087e7b355/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n/bin/bash: /azureml-envs/azureml_58f440cd5db21b9ab3c363f087e7b355/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n2023-08-08T19:14:12,767994423+00:00 - rsyslog/run \n2023-08-08T19:14:12,776993918+00:00 - gunicorn/run \nbash: /azureml-envs/azureml_58f440cd5db21b9ab3c363f087e7b355/lib/libtinfo.so.6: no version information available (required by bash)\n2023-08-08T19:14:12,781754615+00:00 | gunicorn/run | \n2023-08-08T19:14:12,783397515+00:00 | gunicorn/run | ###############################################\n2023-08-08T19:14:12,784923414+00:00 | gunicorn/run | AzureML Container Runtime Information\n2023-08-08T19:14:12,790125411+00:00 | gunicorn/run | ###############################################\n2023-08-08T19:14:12,791653610+00:00 | gunicorn/run | \n2023-08-08T19:14:12,796977407+00:00 | gunicorn/run | \n2023-08-08T19:14:12,808835200+00:00 | gunicorn/run | AzureML image information: openmpi4.1.0-ubuntu20.04, Materializaton Build:20230509.v1\n2023-08-08T19:14:12,808835200+00:00 - nginx/run \n2023-08-08T19:14:12,813653297+00:00 | gunicorn/run | \n2023-08-08T19:14:12,815189997+00:00 | gunicorn/run | \n2023-08-08T19:14:12,821846593+00:00 | gunicorn/run | PATH environment variable: /azureml-envs/azureml_58f440cd5db21b9ab3c363f087e7b355/bin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n2023-08-08T19:14:12,823354993+00:00 | gunicorn/run | PYTHONPATH environment variable: \n2023-08-08T19:14:12,824791493+00:00 | gunicorn/run | \n2023-08-08T19:14:14,288170195+00:00 | gunicorn/run | CONDAPATH environment variable: /opt/miniconda\n\n# conda environments:\n#\n                      *  /azureml-envs/azureml_58f440cd5db21b9ab3c363f087e7b355\nbase                     /opt/miniconda\n\n2023-08-08T19:14:16,554865995+00:00 | gunicorn/run | \n2023-08-08T19:14:16,559377595+00:00 | gunicorn/run | Pip Dependencies (before dynamic installation)\n\nadal==1.2.7\nargcomplete==2.1.2\nattrs==23.1.0\nazure-common==1.1.28\nazure-core==1.28.0\nazure-graphrbac==0.61.1\nazure-identity==1.13.0\nazure-mgmt-authorization==3.0.0\nazure-mgmt-containerregistry==10.1.0\nazure-mgmt-core==1.4.0\nazure-mgmt-keyvault==10.2.3\nazure-mgmt-resource==22.0.0\nazure-mgmt-storage==21.0.0\nazureml==0.2.7\nazureml-core==1.52.0\nazureml-dataprep==4.11.7\nazureml-dataprep-native==38.0.0\nazureml-dataprep-rslex==2.18.6\nazureml-dataset-runtime==1.52.0\nazureml-defaults==1.52.0\nazureml-inference-server-http==0.8.4\nbackports.tempfile==1.0\nbackports.weakref==1.0.post1\nbcrypt==4.0.1\ncachetools==5.3.1\ncertifi @ file:///croot/certifi_1671487769961/work/certifi\ncffi==1.15.1\ncharset-normalizer==3.2.0\nclick==8.1.6\ncloudpickle==2.2.1\ncontextlib2==21.6.0\ncryptography==41.0.3\ndistro==1.8.0\ndocker==6.1.3\ndotnetcore2==3.1.23\nFlask==2.2.5\nFlask-Cors==3.0.10\nfusepy==3.0.1\ngoogle-api-core==2.11.1\ngoogle-auth==2.22.0\ngoogleapis-common-protos==1.60.0\ngunicorn==20.1.0\nhumanfriendly==10.0\nidna==3.4\nimportlib-metadata==6.8.0\nimportlib-resources==6.0.1\ninference-schema==1.5.1\nisodate==0.6.1\nitsdangerous==2.1.2\njeepney==0.8.0\nJinja2==3.1.2\njmespath==1.0.1\njoblib==1.3.1\njsonpickle==3.0.1\njsonschema==4.19.0\njsonschema-specifications==2023.7.1\nknack==0.10.1\nMarkupSafe==2.1.3\nmsal==1.23.0\nmsal-extensions==1.0.0\nmsrest==0.7.1\nmsrestazure==0.6.4\nndg-httpsclient==0.5.1\nnumpy==1.23.5\noauthlib==3.2.2\nopencensus==0.11.2\nopencensus-context==0.1.3\nopencensus-ext-azure==1.1.9\npackaging==23.0\npandas==2.0.3\nparamiko==3.3.1\npathspec==0.11.2\npkginfo==1.9.6\npkgutil_resolve_name==1.3.10\nportalocker==2.7.0\nprotobuf==4.23.4\npsutil==5.9.5\npyarrow==11.0.0\npyasn1==0.5.0\npyasn1-modules==0.3.0\npycparser==2.21\npydantic==1.10.12\nPygments==2.16.1\nPyJWT==2.8.0\nPyNaCl==1.5.0\npyOpenSSL==23.2.0\nPySocks==1.7.1\npython-dateutil==2.8.2\npytz==2023.3\nPyYAML==6.0.1\nreferencing==0.30.2\nrequests==2.31.0\nrequests-oauthlib==1.3.1\nrpds-py==0.9.2\nrsa==4.9\nscikit-learn==1.3.0\nscipy==1.10.1\nSecretStorage==3.3.3\nsix==1.16.0\ntabulate==0.9.0\nthreadpoolctl==3.2.0\ntyping_extensions==4.7.1\ntzdata==2023.3\nurllib3==1.26.16\nwebsocket-client==1.6.1\nWerkzeug==2.3.6\nwrapt==1.12.1\nzipp==3.16.2\n\n2023-08-08T19:14:17,955881295+00:00 | gunicorn/run | \n2023-08-08T19:14:17,957978195+00:00 | gunicorn/run | ###############################################\n2023-08-08T19:14:17,962362295+00:00 | gunicorn/run | Checking if the Python package azureml-inference-server-http is installed\n2023-08-08T19:14:17,964241395+00:00 | gunicorn/run | ###############################################\n2023-08-08T19:14:17,965885995+00:00 | gunicorn/run | \n2023-08-08T19:14:19,958223873+00:00 | gunicorn/run | \n2023-08-08T19:14:19,964597602+00:00 | gunicorn/run | ###############################################\n2023-08-08T19:14:19,967574102+00:00 | gunicorn/run | AzureML Inference Server\n2023-08-08T19:14:19,969875557+00:00 | gunicorn/run | ###############################################\n2023-08-08T19:14:19,976240386+00:00 | gunicorn/run | \n2023-08-08T19:14:21,922080824+00:00 | gunicorn/run | Starting AzureML Inference Server HTTP.\n2023-08-08 19:14:22,336 I [75] azmlinfsrv - Loaded logging config from /azureml-envs/azureml_58f440cd5db21b9ab3c363f087e7b355/lib/python3.8/site-packages/azureml_inference_server_http/logging.json\n2023-08-08 19:14:22,603 I [75] gunicorn.error - Starting gunicorn 20.1.0\n2023-08-08 19:14:22,604 I [75] gunicorn.error - Listening at: http://0.0.0.0:31311 (75)\n2023-08-08 19:14:22,604 I [75] gunicorn.error - Using worker: sync\n2023-08-08 19:14:22,610 I [142] gunicorn.error - Booting worker with pid: 142\n/azureml-envs/azureml_58f440cd5db21b9ab3c363f087e7b355/lib/python3.8/site-packages/azureml_inference_server_http/server/config.py:51: FutureWarning: aliases are no longer used by BaseSettings to define which environment variables to read. Instead use the \"env\" field setting. See https://pydantic-docs.helpmanual.io/usage/settings/#environment-variable-names\n  class AMLInferenceServerConfig(pydantic.BaseSettings):\n\nAzure ML Inferencing HTTP server v0.8.4\n\n\nServer Settings\n---------------\nEntry Script Name: /var/azureml-app/score.py\nModel Directory: /var/azureml-app/azureml-models/hyperdrive_model/3\nConfig File: None\nWorker Count: 1\nWorker Timeout (seconds): 300\nServer Port: 31311\nHealth Port: 31311\nApplication Insights Enabled: false\nApplication Insights Key: None\nInferencing HTTP server version: azmlinfsrv/0.8.4\nCORS for the specified origins: None\nCreate dedicated endpoint for health: None\n\n\nServer Routes\n---------------\nLiveness Probe: GET   127.0.0.1:31311/\nScore:          POST  127.0.0.1:31311/score\n\n2023-08-08 19:14:23,496 I [142] azmlinfsrv - AML_FLASK_ONE_COMPATIBILITY is set. Patched Flask to ensure compatibility with Flask 1.\nInitializing logger\n2023-08-08 19:14:23,502 I [142] azmlinfsrv - Starting up app insights client\n2023-08-08 19:14:24,679 I [142] azmlinfsrv.user_script - Found user script at /var/azureml-app/score.py\n2023-08-08 19:14:24,679 I [142] azmlinfsrv.user_script - run() is not decorated. Server will invoke it with the input in JSON string.\n2023-08-08 19:14:24,680 I [142] azmlinfsrv.user_script - Invoking user's init function\n2023-08-08 19:14:24,680 I [142] azmlinfsrv.print - Loading model from path.\n2023-08-08 19:14:26,005 I [142] azmlinfsrv.print - Loading successful.\n2023-08-08 19:14:26,006 I [142] azmlinfsrv.user_script - Users's init has completed successfully\n2023-08-08 19:14:26,008 I [142] azmlinfsrv.swagger - Swaggers are prepared for the following versions: [2, 3, 3.1].\n2023-08-08 19:14:26,008 I [142] azmlinfsrv - Scoring timeout is set to 60000\n2023-08-08 19:15:12,285 W [142] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n2023-08-08 19:15:12,286 I [142] gunicorn.access - 127.0.0.1 - - [08/Aug/2023:19:15:12 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"Go-http-client/1.1\"\n2023-08-08 19:15:12,292 W [142] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n2023-08-08 19:15:12,293 I [142] azmlinfsrv - GET /swagger.json 200 1.259ms 2210\n2023-08-08 19:15:12,294 I [142] gunicorn.access - 127.0.0.1 - - [08/Aug/2023:19:15:12 +0000] \"GET /swagger.json HTTP/1.0\" 200 2210 \"-\" \"Go-http-client/1.1\"\n2023-08-08 19:15:13,209 W [142] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n2023-08-08 19:15:13,211 I [142] gunicorn.access - 127.0.0.1 - - [08/Aug/2023:19:15:13 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"Go-http-client/1.1\"\n2023-08-08 19:15:13,218 W [142] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n2023-08-08 19:15:13,219 I [142] azmlinfsrv - GET /swagger.json 200 1.102ms 2210\n2023-08-08 19:15:13,220 I [142] gunicorn.access - 127.0.0.1 - - [08/Aug/2023:19:15:13 +0000] \"GET /swagger.json HTTP/1.0\" 200 2210 \"-\" \"Go-http-client/1.1\"\n2023-08-08 19:19:29,291 W [142] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n2023-08-08 19:19:29,303 I [142] azmlinfsrv - POST /score 200 11.714ms 9\n2023-08-08 19:19:29,304 I [142] gunicorn.access - 127.0.0.1 - - [08/Aug/2023:19:19:29 +0000] \"POST /score HTTP/1.0\" 200 9 \"-\" \"python-requests/2.31.0\"\n2023-08-08 19:19:35,812 W [142] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n2023-08-08 19:19:35,820 I [142] azmlinfsrv - POST /score 200 7.738ms 9\n2023-08-08 19:19:35,820 I [142] gunicorn.access - 127.0.0.1 - - [08/Aug/2023:19:19:35 +0000] \"POST /score HTTP/1.0\" 200 9 \"-\" \"python-requests/2.31.0\"\n2023-08-08 19:19:44,995 W [142] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n2023-08-08 19:19:45,004 I [142] azmlinfsrv - POST /score 200 8.699ms 9\n2023-08-08 19:19:45,005 I [142] gunicorn.access - 127.0.0.1 - - [08/Aug/2023:19:19:45 +0000] \"POST /score HTTP/1.0\" 200 9 \"-\" \"python-requests/2.31.0\"\n2023-08-08 19:20:16,699 W [142] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n2023-08-08 19:20:16,705 I [142] azmlinfsrv - POST /score 200 6.075ms 9\n2023-08-08 19:20:16,707 I [142] gunicorn.access - 127.0.0.1 - - [08/Aug/2023:19:20:16 +0000] \"POST /score HTTP/1.0\" 200 9 \"-\" \"python-requests/2.31.0\"\n2023-08-08 19:21:01,415 W [142] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n2023-08-08 19:21:01,424 I [142] azmlinfsrv - POST /score 200 9.376ms 9\n2023-08-08 19:21:01,426 I [142] gunicorn.access - 127.0.0.1 - - [08/Aug/2023:19:21:01 +0000] \"POST /score HTTP/1.0\" 200 9 \"-\" \"python-requests/2.31.0\"\n2023-08-08 19:21:18,306 W [142] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n2023-08-08 19:21:18,316 I [142] azmlinfsrv - POST /score 200 10.223ms 9\n2023-08-08 19:21:18,317 I [142] gunicorn.access - 127.0.0.1 - - [08/Aug/2023:19:21:18 +0000] \"POST /score HTTP/1.0\" 200 9 \"-\" \"python-requests/2.31.0\"\n\n"
        }
      ],
      "execution_count": 37,
      "metadata": {
        "gather": {
          "logged": 1691522527483
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Delete and shutdown webservice:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "service.delete()\n",
        "model.delete()\n",
        "compute_target.delete()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Submission Checklist**\n",
        "- I have registered the model.\n",
        "- I have deployed the model with the best accuracy as a webservice.\n",
        "- I have tested the webservice by sending a request to the model endpoint.\n",
        "- I have deleted the webservice and shutdown all the computes that I have used.\n",
        "- I have taken a screenshot showing the model endpoint as active.\n",
        "- The project includes a file containing the environment details.\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}